{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jintubhuyan-2000/ML-XAI_ForestFire/blob/main/Forest_TemporalSplit__FinalRevised2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown --quiet\n",
        "\n",
        "# Use gdown to download the folder\n",
        "!gdown \"https://drive.google.com/drive/u/0/folders/1ZPvCvLcy68RGEFKIA1elHrDdzMSXKZ8a\" --folder"
      ],
      "metadata": {
        "id": "fttZ8xJdDezt",
        "outputId": "e49f3952-b9d9-4354-faab-eee98944ac65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fttZ8xJdDezt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 1q0JYs5vwwDkEN3gVQBc4-7oAKGx6J189 AccuracyStats_2025_grassland.csv\n",
            "Processing file 1wgWqbfJ5_qMgH2TgqbIRfgBseKvpUFJ2 ConfusionMatrix_2025_grassland.csv\n",
            "Processing file 1CYhNkpQr_9q8G947aTYd41X26B_yzGh1 FireProbStats_PerDistrict_grassland.csv\n",
            "Processing file 17GP1DDg1USLDjZAv-BBH-QSJlQjzAPSu RF_RegionTransfer_Test_grassland.csv\n",
            "Processing file 1Y08p-xgwuWZNR20Mx2gbB27MZNoUZH_w RF_SpatialCV_Test_grassland.csv\n",
            "Processing file 19xIgV46X3CI7f1txivigEZO7yioXOFxF RF_TemporalSplit_Test2025_grassland.csv\n",
            "Processing file 1I4JLP1qu5AuP80uHISDV_asbihnH9pYr TestPoints_Predictors_grassland.csv\n",
            "Processing file 1drsd-aZRdiKnNblLniHCuN7sGdc69dFG TrainPoints_Predictors_grassland.csv\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1q0JYs5vwwDkEN3gVQBc4-7oAKGx6J189\n",
            "To: /content/Validation Datasets/AccuracyStats_2025_grassland.csv\n",
            "100% 127/127 [00:00<00:00, 410kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wgWqbfJ5_qMgH2TgqbIRfgBseKvpUFJ2\n",
            "To: /content/Validation Datasets/ConfusionMatrix_2025_grassland.csv\n",
            "100% 134/134 [00:00<00:00, 580kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CYhNkpQr_9q8G947aTYd41X26B_yzGh1\n",
            "To: /content/Validation Datasets/FireProbStats_PerDistrict_grassland.csv\n",
            "100% 3.62M/3.62M [00:00<00:00, 71.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17GP1DDg1USLDjZAv-BBH-QSJlQjzAPSu\n",
            "To: /content/Validation Datasets/RF_RegionTransfer_Test_grassland.csv\n",
            "100% 470k/470k [00:00<00:00, 20.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y08p-xgwuWZNR20Mx2gbB27MZNoUZH_w\n",
            "To: /content/Validation Datasets/RF_SpatialCV_Test_grassland.csv\n",
            "100% 470k/470k [00:00<00:00, 49.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19xIgV46X3CI7f1txivigEZO7yioXOFxF\n",
            "To: /content/Validation Datasets/RF_TemporalSplit_Test2025_grassland.csv\n",
            "100% 585k/585k [00:00<00:00, 63.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1I4JLP1qu5AuP80uHISDV_asbihnH9pYr\n",
            "To: /content/Validation Datasets/TestPoints_Predictors_grassland.csv\n",
            "100% 503k/503k [00:00<00:00, 74.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1drsd-aZRdiKnNblLniHCuN7sGdc69dFG\n",
            "To: /content/Validation Datasets/TrainPoints_Predictors_grassland.csv\n",
            "100% 103k/103k [00:00<00:00, 79.3MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "106c6abc-8bdb-417c-ad86-f0f8470c6718",
      "metadata": {
        "id": "106c6abc-8bdb-417c-ad86-f0f8470c6718",
        "outputId": "66ea0652-0c6e-4c51-a05c-d233f5794ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CSV: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Validation Datasets/RF_SpatialCV_Test_grassland.csv\n",
            "Detected columns -> label: class , prob: classification\n",
            "No stratum column detected - will evaluate overall only. If you have 'forest'/'grassland' values, add as 'landcover' or 'class_name'.\n",
            "Running 10 runs with seeds: [1281540326, 1005233768, 2011547310, 1367058049, 1542280147, 90017157, 581114276, 1258272007, 2134214070, 1923482161]\n",
            "Saved ROC with ribbons: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/roc_curve_mean_sd.png\n",
            "Saved PR with ribbons: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/pr_curve_mean_sd.png\n",
            "Saved Top-K curve with ribbons: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/topk_curve_mean_sd.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2011836677.py:462: RuntimeWarning: Mean of empty slice\n",
            "  mean_bin_obs = np.nanmean(cal_bin_obs_matrix, axis=0)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved reliability plot with ribbons: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/reliability_mean_sd.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2011836677.py:505: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(shap_values[1] if isinstance(shap_values, list) else shap_values, Xs, show=False, plot_type='bar')\n",
            "/usr/local/lib/python3.12/dist-packages/shap/plots/_beeswarm.py:723: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n",
            "/usr/local/lib/python3.12/dist-packages/shap/plots/_beeswarm.py:743: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHAP dependence_plot failed: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 50\n",
            "Region-transfer / Temporal-style Multi-run Evaluation\n",
            "File: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Validation Datasets/RF_SpatialCV_Test_grassland.csv\n",
            "Total original samples: 2462, Overall positive rate: 0.8115\n",
            "Sampling method: stratified_bootstrap\n",
            "Number of runs (K): 10\n",
            "Base seed (document for reproducibility): 20250908\n",
            "Seeds used: [1281540326, 1005233768, 2011547310, 1367058049, 1542280147, 90017157, 581114276, 1258272007, 2134214070, 1923482161]\n",
            "\n",
            "Metrics per-run saved to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/metrics_per_run.csv\n",
            "Aggregated metrics saved to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/metrics_aggregated_by_stratum.csv (mean ± sd ± 95%CI)\n",
            "Top-K per-run saved to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/topk_per_run.csv\n",
            "Top-K aggregated saved to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/topk_aggregated.csv\n",
            "ROC plot (mean ± SD): /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/roc_curve_mean_sd.png\n",
            "PR plot (mean ± SD): /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/pr_curve_mean_sd.png\n",
            "Reliability plot (mean ± SD): /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/reliability_mean_sd.png\n",
            "Top-K plot (mean ± SD): /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5/topk_curve_mean_sd.png\n",
            "Outputs written to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/grassland/Results/Temporal_Split_V5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Wildfire RF Evaluation & SHAP Analysis (multi-run + uncertainty)\n",
        "# Paste into a Jupyter cell. Requires: pandas, numpy, matplotlib, scikit-learn\n",
        "# Optional: shap (pip install shap) for SHAP outputs.\n",
        "# Outputs: metrics CSV (per-run + aggregated), topk CSV, curves, summary text.\n",
        "# Author: adapted for multi-run uncertainty & reproducibility\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, roc_curve,\n",
        "    average_precision_score, precision_recall_curve,\n",
        "    brier_score_loss, f1_score, precision_score, recall_score\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "# Optional SHAP\n",
        "try:\n",
        "    import shap\n",
        "    SHAP_AVAILABLE = True\n",
        "except Exception:\n",
        "    SHAP_AVAILABLE = False\n",
        "\n",
        "# ----------------- CONFIG -----------------\n",
        "search_dirs = [\n",
        "    r\"/content/Validation Datasets\",\n",
        "]\n",
        "OUT_DIR = Path(r\"/content/drive/MyDrive/California_Fire_MS/Fire_Risk_Validation/forest/Results/Temporal_Split_V5\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# resampling / reproducibility settings\n",
        "K_RUNS = 10                       # set between 5-10 (user request)\n",
        "BASE_SEED = 20250908              # document this seed in Methods (changeable)\n",
        "SAMPLING_METHOD = \"stratified_bootstrap\"  # options: 'stratified_bootstrap' or 'subsample_no_replacement'\n",
        "TEST_SAMPLE_FRACTION = 1.0        # for subsampling (if used). For bootstrap keep =1.0\n",
        "\n",
        "# Settings for curves / interpolation\n",
        "ROC_FPR_GRID = np.linspace(0,1,200)\n",
        "PR_RECALL_GRID = np.linspace(0,1,200)\n",
        "CAL_PROB_BINS = np.linspace(0.0, 1.0, 11)  # 10 bins for reliability diagram\n",
        "TOPK_PERCENTS = [1,5,10,20,30,40,50]\n",
        "\n",
        "# Filenames\n",
        "METRICS_PER_RUN_CSV = OUT_DIR / \"metrics_per_run.csv\"\n",
        "METRICS_AGG_CSV = OUT_DIR / \"metrics_aggregated_by_stratum.csv\"\n",
        "TOPK_PER_RUN_CSV = OUT_DIR / \"topk_per_run.csv\"\n",
        "TOPK_AGG_CSV = OUT_DIR / \"topk_aggregated.csv\"\n",
        "SUMMARY_TXT = OUT_DIR / \"summary_report_multi_run.txt\"\n",
        "\n",
        "# ----------------- Helpers -----------------\n",
        "def find_candidate_csv(dirs):\n",
        "    candidates = []\n",
        "    for d in dirs:\n",
        "        for p in Path(d).rglob(\"*.csv\"):\n",
        "            candidates.append(p)\n",
        "    if not candidates:\n",
        "        return None\n",
        "    prioritized = [p for p in candidates if any(k in p.name.lower() for k in (\"test2025\",\"test_2025\",\"rf_regiontransfer\",\"rf_spatialcv_test\",\"rf_region_transfer_test\",\"rf_spatialcv_test\",\"rf_\"))]\n",
        "    if prioritized:\n",
        "        return prioritized[0]\n",
        "    prioritized = [p for p in candidates if any(k in p.name.lower() for k in (\"test\",\"2025\",\"regiontransfer\",\"region_transfer\"))]\n",
        "    if prioritized:\n",
        "        return prioritized[0]\n",
        "    return candidates[0]\n",
        "\n",
        "def topk_capture(y_true, y_prob, ks=TOPK_PERCENTS):\n",
        "    out = []\n",
        "    order = np.argsort(-y_prob)\n",
        "    y_true_sorted = np.array(y_true)[order]\n",
        "    total_pos = float(y_true_sorted.sum())\n",
        "    n = len(y_true_sorted)\n",
        "    for k in ks:\n",
        "        frac = k / 100.0\n",
        "        top_n = max(1, int(math.ceil(n * frac)))\n",
        "        captured = int(y_true_sorted[:top_n].sum())\n",
        "        capture_rate = (captured / total_pos) if total_pos > 0 else np.nan\n",
        "        out.append({\n",
        "            \"top_%\": k,\n",
        "            \"top_n\": top_n,\n",
        "            \"pos_captured_count\": captured,\n",
        "            \"pos_captured_frac\": capture_rate\n",
        "        })\n",
        "    return pd.DataFrame(out)\n",
        "\n",
        "def interpolate_curve(x, y, x_grid):\n",
        "    # simple interpolation (assumes x sorted ascending)\n",
        "    # clamp to valid range\n",
        "    xp = np.clip(x, 0.0, 1.0)\n",
        "    yp = np.clip(y, 0.0, 1.0)\n",
        "    # remove duplicated x for interpolation\n",
        "    xp_unique, idx = np.unique(xp, return_index=True)\n",
        "    yp_unique = yp[idx]\n",
        "    # If too few unique points, fallback\n",
        "    if len(xp_unique) < 2:\n",
        "        return np.full_like(x_grid, yp_unique[0] if len(yp_unique)>0 else np.nan)\n",
        "    return np.interp(x_grid, xp_unique, yp_unique)\n",
        "\n",
        "# ----------------- Locate CSV -----------------\n",
        "csv_path = find_candidate_csv(search_dirs)\n",
        "if csv_path is None:\n",
        "    raise FileNotFoundError(f\"No CSV found in {search_dirs}. Place your exported CSV(s) in one of those folders.\")\n",
        "print(\"Using CSV:\", csv_path)\n",
        "\n",
        "# ----------------- Load & detect columns -----------------\n",
        "df_orig = pd.read_csv(csv_path)\n",
        "cols = list(df_orig.columns)\n",
        "y_true_col = None\n",
        "y_prob_col = None\n",
        "# heuristics for truth and prob columns\n",
        "for c in cols:\n",
        "    lc = c.lower().strip()\n",
        "    if lc in ('class','label','y','ground_truth','is_fire','fire') and y_true_col is None:\n",
        "        y_true_col = c\n",
        "    if lc in ('classification','probability','prob','pred','pred_prob','probability_1') and y_prob_col is None:\n",
        "        y_prob_col = c\n",
        "# fallback heuristics\n",
        "if y_true_col is None:\n",
        "    for c in cols:\n",
        "        if 'class' in c.lower() or c.lower().startswith('label'):\n",
        "            y_true_col = c\n",
        "            break\n",
        "if y_prob_col is None:\n",
        "    for c in cols:\n",
        "        if any(k in c.lower() for k in ('prob','classification','pred')):\n",
        "            y_prob_col = c\n",
        "            break\n",
        "\n",
        "if y_true_col is None or y_prob_col is None:\n",
        "    raise ValueError(f\"Could not auto-detect required columns. Found: {cols}\\nExpected a 'class' (ground truth) and 'classification'/'probability' column.\")\n",
        "print(\"Detected columns -> label:\", y_true_col, \", prob:\", y_prob_col)\n",
        "\n",
        "# optional stratum column detection (forest / grassland)\n",
        "stratum_col = None\n",
        "for candidate in ['landcover','land_cover','lc','class_name','stratum','habitat','lcc']:\n",
        "    if candidate in [c.lower() for c in cols]:\n",
        "        # pick original-case column name\n",
        "        for c in cols:\n",
        "            if c.lower()==candidate:\n",
        "                stratum_col = c\n",
        "                break\n",
        "        break\n",
        "if stratum_col:\n",
        "    print(\"Detected stratum column:\", stratum_col)\n",
        "else:\n",
        "    print(\"No stratum column detected - will evaluate overall only. If you have 'forest'/'grassland' values, add as 'landcover' or 'class_name'.\")\n",
        "\n",
        "# ----------------- Data cleaning -----------------\n",
        "df_orig = df_orig.dropna(subset=[y_true_col, y_prob_col]).copy()\n",
        "df_orig['y_true'] = df_orig[y_true_col].astype(int)\n",
        "df_orig['y_prob'] = pd.to_numeric(df_orig[y_prob_col], errors='coerce').clip(0,1)\n",
        "df_orig = df_orig.dropna(subset=['y_prob']).reset_index(drop=True)\n",
        "n_total = len(df_orig)\n",
        "pos_rate_total = df_orig['y_true'].mean()\n",
        "\n",
        "# ----------------- Multi-run evaluation -----------------\n",
        "rng = np.random.default_rng(BASE_SEED)\n",
        "seeds = [int(r) for r in rng.integers(0, 2**31-1, size=K_RUNS)]\n",
        "print(f\"Running {K_RUNS} runs with seeds: {seeds}\")\n",
        "\n",
        "metrics_rows = []\n",
        "topk_rows = []\n",
        "\n",
        "# We'll store per-run interpolated curves for averaging\n",
        "roc_tpr_matrix = np.zeros((K_RUNS, len(ROC_FPR_GRID)))\n",
        "pr_prec_matrix = np.zeros((K_RUNS, len(PR_RECALL_GRID)))\n",
        "cal_bin_obs_matrix = np.zeros((K_RUNS, len(CAL_PROB_BINS)-1))  # one less than edges\n",
        "topk_matrix = np.zeros((K_RUNS, len(TOPK_PERCENTS)))\n",
        "\n",
        "for run_idx, seed in enumerate(seeds):\n",
        "    np.random.seed(seed)\n",
        "    if SAMPLING_METHOD == 'stratified_bootstrap':\n",
        "        # resample indices stratified by y_true\n",
        "        idx_list = []\n",
        "        for cls in df_orig['y_true'].unique():\n",
        "            cls_idx = df_orig.index[df_orig['y_true']==cls].tolist()\n",
        "            if len(cls_idx)==0:\n",
        "                continue\n",
        "            # sample with replacement same size as original class count\n",
        "            s = np.random.choice(cls_idx, size=len(cls_idx), replace=True)\n",
        "            idx_list.extend(s.tolist())\n",
        "        sampled_idx = np.array(idx_list)\n",
        "    elif SAMPLING_METHOD == 'subsample_no_replacement':\n",
        "        # random subsample without replacement\n",
        "        n_take = int(math.ceil(n_total * TEST_SAMPLE_FRACTION))\n",
        "        sampled_idx = np.random.choice(df_orig.index, size=n_take, replace=False)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown SAMPLING_METHOD. Use 'stratified_bootstrap' or 'subsample_no_replacement'.\")\n",
        "\n",
        "    df = df_orig.loc[sampled_idx].reset_index(drop=True)\n",
        "\n",
        "    # compute scalar metrics\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(df['y_true'], df['y_prob'])\n",
        "    except Exception:\n",
        "        roc_auc = np.nan\n",
        "    try:\n",
        "        pr_auc = average_precision_score(df['y_true'], df['y_prob'])\n",
        "    except Exception:\n",
        "        pr_auc = np.nan\n",
        "    brier = brier_score_loss(df['y_true'], df['y_prob'])\n",
        "    # compute threshold-based metrics at chosen threshold (e.g., 0.5 or choose optimal)\n",
        "    thresh = 0.5\n",
        "    y_pred = (df['y_prob'] >= thresh).astype(int)\n",
        "    f1 = f1_score(df['y_true'], y_pred, zero_division=0)\n",
        "    prec = precision_score(df['y_true'], y_pred, zero_division=0)\n",
        "    rec = recall_score(df['y_true'], y_pred, zero_division=0)\n",
        "\n",
        "    # Save metrics\n",
        "    metrics_rows.append({\n",
        "        \"run\": run_idx,\n",
        "        \"seed\": seed,\n",
        "        \"n_samples\": len(df),\n",
        "        \"positive_rate\": float(df['y_true'].mean()),\n",
        "        \"roc_auc\": float(roc_auc),\n",
        "        \"pr_auc\": float(pr_auc),\n",
        "        \"brier\": float(brier),\n",
        "        \"threshold\": thresh,\n",
        "        \"f1_at_0.5\": float(f1),\n",
        "        \"precision_at_0.5\": float(prec),\n",
        "        \"recall_at_0.5\": float(rec)\n",
        "    })\n",
        "\n",
        "    # ROC curve -> interpolate TPR on common FPR grid\n",
        "    try:\n",
        "        fpr, tpr, _ = roc_curve(df['y_true'], df['y_prob'])\n",
        "        tpr_interp = interpolate_curve(fpr, tpr, ROC_FPR_GRID)\n",
        "    except Exception:\n",
        "        tpr_interp = np.full_like(ROC_FPR_GRID, np.nan)\n",
        "    roc_tpr_matrix[run_idx,:] = tpr_interp\n",
        "\n",
        "    # PR curve -> interpolate Precision on common Recall grid\n",
        "    try:\n",
        "        precision, recall, _ = precision_recall_curve(df['y_true'], df['y_prob'])\n",
        "        # precision_recall_curve returns precision values for thresholds; recall is decreasing\n",
        "        # ensure recall sorted ascending for interpolation\n",
        "        recall_sort_idx = np.argsort(recall)\n",
        "        precision_sorted = precision[recall_sort_idx]\n",
        "        recall_sorted = recall[recall_sort_idx]\n",
        "        prec_interp = interpolate_curve(recall_sorted, precision_sorted, PR_RECALL_GRID)\n",
        "    except Exception:\n",
        "        prec_interp = np.full_like(PR_RECALL_GRID, np.nan)\n",
        "    pr_prec_matrix[run_idx,:] = prec_interp\n",
        "\n",
        "    # Calibration reliability -> bin predicted probabilities into CAL_PROB_BINS\n",
        "    try:\n",
        "        prob_true, prob_pred = calibration_curve(df['y_true'], df['y_prob'], n_bins=len(CAL_PROB_BINS)-1, strategy='uniform')\n",
        "        # calibration_curve returns prob_true (observed) and prob_pred (predicted mean)\n",
        "        # We will compute observed frequency per uniform bin using pandas cut to ensure alignment with edges\n",
        "        df['prob_bin'] = pd.cut(df['y_prob'], bins=CAL_PROB_BINS, include_lowest=True, labels=False)\n",
        "        obs_per_bin = []\n",
        "        for b in range(len(CAL_PROB_BINS)-1):\n",
        "            sel = df['prob_bin']==b\n",
        "            if sel.sum() == 0:\n",
        "                obs_per_bin.append(np.nan)\n",
        "            else:\n",
        "                obs_per_bin.append(df.loc[sel, 'y_true'].mean())\n",
        "        cal_bin_obs_matrix[run_idx,:] = np.array(obs_per_bin, dtype=float)\n",
        "    except Exception:\n",
        "        cal_bin_obs_matrix[run_idx,:] = np.full(len(CAL_PROB_BINS)-1, np.nan)\n",
        "\n",
        "    # Top-K capture\n",
        "    try:\n",
        "        topk_df = topk_capture(df['y_true'].values, df['y_prob'].values, ks=TOPK_PERCENTS)\n",
        "        for j,k in enumerate(TOPK_PERCENTS):\n",
        "            topk_matrix[run_idx,j] = topk_df.loc[topk_df['top_%']==k, 'pos_captured_frac'].values[0]\n",
        "        # record per-run topk in long form\n",
        "        temp = topk_df.copy()\n",
        "        temp['run'] = run_idx\n",
        "        temp['seed'] = seed\n",
        "        topk_rows.append(temp)\n",
        "    except Exception:\n",
        "        topk_matrix[run_idx,:] = np.nan\n",
        "        topk_rows.append(pd.DataFrame())\n",
        "\n",
        "# ----------------- Aggregation -----------------\n",
        "metrics_df = pd.DataFrame(metrics_rows)\n",
        "metrics_df.to_csv(METRICS_PER_RUN_CSV, index=False)\n",
        "\n",
        "# Aggregate metrics overall (mean ± sd, and 95% CI) and by stratum if available\n",
        "def agg_stats(series):\n",
        "    mean = np.nanmean(series)\n",
        "    sd = np.nanstd(series, ddof=1) if np.sum(~np.isnan(series))>1 else np.nan\n",
        "    # 95% CI via t-approx (large K so normal approximation fine)\n",
        "    n = np.sum(~np.isnan(series))\n",
        "    se = sd / math.sqrt(n) if n>0 and not np.isnan(sd) else np.nan\n",
        "    ci95 = 1.96 * se if se is not None else np.nan\n",
        "    return mean, sd, ci95\n",
        "\n",
        "agg_rows = []\n",
        "metrics_to_agg = [\"roc_auc\",\"pr_auc\",\"brier\",\"f1_at_0.5\",\"precision_at_0.5\",\"recall_at_0.5\",\"positive_rate\"]\n",
        "for metric in metrics_to_agg:\n",
        "    mean, sd, ci95 = agg_stats(metrics_df[metric].values)\n",
        "    agg_rows.append({\n",
        "        \"stratum\": \"ALL\",\n",
        "        \"metric\": metric,\n",
        "        \"mean\": mean,\n",
        "        \"sd\": sd,\n",
        "        \"ci95\": ci95\n",
        "    })\n",
        "\n",
        "# If stratum col exists, perform per-stratum aggregation by running the same evaluation across runs restricted to stratum.\n",
        "if stratum_col:\n",
        "    strata = df_orig[stratum_col].dropna().unique().tolist()\n",
        "    for stratum_val in strata:\n",
        "        # For each run, recompute metric restricted to stratum samples from that run's sampled indices.\n",
        "        # Simplest: loop again over seeds and compute metrics per stratum (cheaper copies).\n",
        "        per_stratum_metrics = []\n",
        "        for run_idx, seed in enumerate(seeds):\n",
        "            np.random.seed(seed)\n",
        "            if SAMPLING_METHOD == 'stratified_bootstrap':\n",
        "                idx_list = []\n",
        "                for cls in df_orig['y_true'].unique():\n",
        "                    cls_idx = df_orig.index[df_orig['y_true']==cls].tolist()\n",
        "                    if len(cls_idx)==0:\n",
        "                        continue\n",
        "                    s = np.random.choice(cls_idx, size=len(cls_idx), replace=True)\n",
        "                    idx_list.extend(s.tolist())\n",
        "                sampled_idx = np.array(idx_list)\n",
        "            else:\n",
        "                n_take = int(math.ceil(n_total * TEST_SAMPLE_FRACTION))\n",
        "                sampled_idx = np.random.choice(df_orig.index, size=n_take, replace=False)\n",
        "            df_run = df_orig.loc[sampled_idx]\n",
        "            df_run_stratum = df_run[df_run[stratum_col]==stratum_val]\n",
        "            if len(df_run_stratum)==0:\n",
        "                per_stratum_metrics.append({m: np.nan for m in metrics_to_agg})\n",
        "                continue\n",
        "            try:\n",
        "                roc_auc = roc_auc_score(df_run_stratum['y_true'], df_run_stratum['y_prob'])\n",
        "            except Exception:\n",
        "                roc_auc = np.nan\n",
        "            try:\n",
        "                pr_auc = average_precision_score(df_run_stratum['y_true'], df_run_stratum['y_prob'])\n",
        "            except Exception:\n",
        "                pr_auc = np.nan\n",
        "            brier = brier_score_loss(df_run_stratum['y_true'], df_run_stratum['y_prob'])\n",
        "            thresh = 0.5\n",
        "            y_pred = (df_run_stratum['y_prob']>=thresh).astype(int)\n",
        "            f1 = f1_score(df_run_stratum['y_true'], y_pred, zero_division=0)\n",
        "            prec = precision_score(df_run_stratum['y_true'], y_pred, zero_division=0)\n",
        "            rec = recall_score(df_run_stratum['y_true'], y_pred, zero_division=0)\n",
        "            per_stratum_metrics.append({\n",
        "                \"roc_auc\": roc_auc, \"pr_auc\": pr_auc, \"brier\": brier,\n",
        "                \"f1_at_0.5\": f1, \"precision_at_0.5\": prec, \"recall_at_0.5\": rec,\n",
        "                \"positive_rate\": float(df_run_stratum['y_true'].mean())\n",
        "            })\n",
        "        per_stratum_df = pd.DataFrame(per_stratum_metrics)\n",
        "        for metric in metrics_to_agg:\n",
        "            mean, sd, ci95 = agg_stats(per_stratum_df[metric].values)\n",
        "            agg_rows.append({\n",
        "                \"stratum\": str(stratum_val),\n",
        "                \"metric\": metric,\n",
        "                \"mean\": mean,\n",
        "                \"sd\": sd,\n",
        "                \"ci95\": ci95\n",
        "            })\n",
        "\n",
        "agg_df = pd.DataFrame(agg_rows)\n",
        "agg_df.to_csv(METRICS_AGG_CSV, index=False)\n",
        "\n",
        "# ----------------- Top-K aggregation -----------------\n",
        "topk_all = pd.concat([t.assign(run=int(t['run'].iloc[0]) ) if not t.empty else pd.DataFrame() for t in topk_rows], ignore_index=True, sort=False)\n",
        "if not topk_all.empty:\n",
        "    topk_all.to_csv(TOPK_PER_RUN_CSV, index=False)\n",
        "# aggregate across runs\n",
        "topk_agg = []\n",
        "for j,k in enumerate(TOPK_PERCENTS):\n",
        "    vals = topk_matrix[:,j]\n",
        "    mean, sd, ci95 = agg_stats(vals)\n",
        "    topk_agg.append({\"top_%\": k, \"mean_frac\": mean, \"sd\": sd, \"ci95\": ci95})\n",
        "topk_agg_df = pd.DataFrame(topk_agg)\n",
        "topk_agg_df.to_csv(TOPK_AGG_CSV, index=False)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ----------------- Plotting with ribbons -----------------\n",
        "# ROC: mean TPR across runs at fixed FPR grid, with ribbon ±1 SD\n",
        "mean_tpr = np.nanmean(roc_tpr_matrix, axis=0)\n",
        "sd_tpr = np.nanstd(roc_tpr_matrix, axis=0, ddof=1)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(ROC_FPR_GRID, mean_tpr, label=f\"Mean ROC (n={K_RUNS})\", linewidth=2)\n",
        "plt.fill_between(ROC_FPR_GRID, mean_tpr - sd_tpr, mean_tpr + sd_tpr, alpha=0.2)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
        "\n",
        "# ---- Font size adjustments (16 pt) ----\n",
        "plt.xlabel('False Positive Rate', fontsize=18)\n",
        "plt.ylabel('True Positive Rate', fontsize=18)\n",
        "plt.title('ROC Curve (mean ± SD)', fontsize=18)\n",
        "plt.legend(loc='lower right', fontsize=18)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.xticks(fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "\n",
        "plt.tight_layout()\n",
        "roc_path = OUT_DIR / 'roc_curve_mean_sd.png'\n",
        "plt.savefig(roc_path, dpi=200)\n",
        "plt.close()\n",
        "print(\"Saved ROC with ribbons:\", roc_path)\n",
        "\n",
        "\n",
        "# ----------------- Precision-Recall Curve -----------------\n",
        "mean_prec = np.nanmean(pr_prec_matrix, axis=0)\n",
        "sd_prec = np.nanstd(pr_prec_matrix, axis=0, ddof=1)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(PR_RECALL_GRID, mean_prec, label=f\"Mean PR (n={K_RUNS})\", linewidth=2)\n",
        "plt.fill_between(PR_RECALL_GRID, mean_prec - sd_prec, mean_prec + sd_prec, alpha=0.2)\n",
        "\n",
        "plt.xlabel('Recall', fontsize=18)\n",
        "plt.ylabel('Precision', fontsize=18)\n",
        "plt.title('Precision-Recall Curve (mean ± SD)', fontsize=18)\n",
        "plt.legend(loc='upper right', fontsize=18)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.xticks(fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "\n",
        "plt.tight_layout()\n",
        "pr_path = OUT_DIR / 'pr_curve_mean_sd.png'\n",
        "plt.savefig(pr_path, dpi=200)\n",
        "plt.close()\n",
        "print(\"Saved PR with ribbons:\", pr_path)\n",
        "\n",
        "\n",
        "# ----------------- Top-K: Mean Capture Fraction -----------------\n",
        "mean_topk = np.nanmean(topk_matrix, axis=0)\n",
        "sd_topk = np.nanstd(topk_matrix, axis=0, ddof=1)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(TOPK_PERCENTS, mean_topk, marker='o', color='tab:blue', linewidth=1.8,\n",
        "         label='Mean Top-K capture')\n",
        "plt.fill_between(TOPK_PERCENTS,\n",
        "                 mean_topk - sd_topk,\n",
        "                 mean_topk + sd_topk,\n",
        "                 color='tab:blue',\n",
        "                 alpha=0.2,\n",
        "                 label='± SD')\n",
        "\n",
        "plt.xlabel('Top-k percent of highest risk area', fontsize=18)\n",
        "plt.ylabel('Fraction of fires captured', fontsize=18)\n",
        "plt.title('Top-K Capture (mean ± SD)', fontsize=18)\n",
        "plt.ylim(0, 1)\n",
        "plt.xlim(0, 50)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend(loc='lower right', fontsize=14)\n",
        "plt.xticks(fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "\n",
        "plt.tight_layout()\n",
        "topk_plot_path = OUT_DIR / 'topk_curve_mean_sd.png'\n",
        "plt.savefig(topk_plot_path, dpi=200)\n",
        "plt.close()\n",
        "print(\"Saved Top-K curve with ribbons:\", topk_plot_path)\n",
        "\n",
        "\n",
        "# ----------------- Reliability Plot -----------------\n",
        "cal_bin_centers = (CAL_PROB_BINS[:-1] + CAL_PROB_BINS[1:]) / 2.0\n",
        "mean_bin_obs = np.nanmean(cal_bin_obs_matrix, axis=0)\n",
        "sd_bin_obs = np.nanstd(cal_bin_obs_matrix, axis=0, ddof=1)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(cal_bin_centers, mean_bin_obs, marker='o', linewidth=2, label='Mean calibration')\n",
        "plt.fill_between(cal_bin_centers, mean_bin_obs - sd_bin_obs, mean_bin_obs + sd_bin_obs, alpha=0.2)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect')\n",
        "\n",
        "plt.xlabel('Predicted probability (bin center)', fontsize=18)\n",
        "plt.ylabel('Observed frequency', fontsize=18)\n",
        "plt.title('Reliability Diagram (mean ± SD)', fontsize=18)\n",
        "plt.legend(fontsize=18)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.xticks(fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "\n",
        "plt.tight_layout()\n",
        "rel_path = OUT_DIR / 'reliability_mean_sd.png'\n",
        "plt.savefig(rel_path, dpi=200)\n",
        "plt.close()\n",
        "print(\"Saved reliability plot with ribbons:\", rel_path)\n",
        "\n",
        "\n",
        "# ----------------- Optional SHAP (single-run sample) - unchanged logic but left optional -----------------\n",
        "shap_outputs = {}\n",
        "meta_like = set([y_true_col, y_prob_col, 'y_true','y_prob','system:index','.geo','longitude','lat','latitude','year','quadrant'])\n",
        "feature_cols = [c for c in df_orig.columns if c not in meta_like and np.issubdtype(df_orig[c].dtype, np.number)]\n",
        "if SHAP_AVAILABLE and len(feature_cols) >= 2:\n",
        "    try:\n",
        "        X = df_orig[feature_cols].copy().fillna(0)\n",
        "        y = df_orig['y_true'].copy()\n",
        "        # small train/test split for SHAP model building\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        from sklearn.ensemble import RandomForestClassifier\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "        rf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42, class_weight='balanced_subsample')\n",
        "        rf.fit(X_train, y_train)\n",
        "        explainer = shap.TreeExplainer(rf)\n",
        "        Xs = X_val.sample(min(5000, len(X_val)), random_state=42)\n",
        "        shap_values = explainer.shap_values(Xs)\n",
        "        # Summary bar\n",
        "        try:\n",
        "            plt.figure(figsize=(6,6))\n",
        "            shap.summary_plot(shap_values[1] if isinstance(shap_values, list) else shap_values, Xs, show=False, plot_type='bar')\n",
        "            shap_summary_path = OUT_DIR / 'shap_summary_bar.png'\n",
        "            plt.savefig(shap_summary_path, dpi=200, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            shap_outputs['shap_summary'] = str(shap_summary_path)\n",
        "        except Exception as e:\n",
        "            print('SHAP summary_plot failed:', e)\n",
        "        # Dependence for top feature\n",
        "        try:\n",
        "            if isinstance(shap_values, list):\n",
        "                abs_mean = np.mean(np.abs(shap_values[1]), axis=0)\n",
        "            else:\n",
        "                abs_mean = np.mean(np.abs(shap_values), axis=0)\n",
        "            top_idx = int(np.argmax(abs_mean))\n",
        "            top_feat = Xs.columns[top_idx]\n",
        "            plt.figure(figsize=(6,5))\n",
        "            shap.dependence_plot(top_feat, shap_values[1] if isinstance(shap_values, list) else shap_values, Xs, show=False)\n",
        "            shap_dep_path = OUT_DIR / 'shap_dependence_top_feature.png'\n",
        "            plt.savefig(shap_dep_path, dpi=200, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            shap_outputs['top_feature'] = top_feat\n",
        "        except Exception as e:\n",
        "            print('SHAP dependence_plot failed:', e)\n",
        "    except Exception as e:\n",
        "        print('SHAP stage failed:', e)\n",
        "else:\n",
        "    if not SHAP_AVAILABLE:\n",
        "        print('SHAP not installed - skip SHAP outputs. To enable, `pip install shap`.')\n",
        "    else:\n",
        "        print('Not enough numeric features for SHAP or no features found - skipping SHAP.')\n",
        "\n",
        "# ----------------- Save textual summary -----------------\n",
        "report_lines = [\n",
        "    \"Region-transfer / Temporal-style Multi-run Evaluation\",\n",
        "    f\"File: {csv_path}\",\n",
        "    f\"Total original samples: {n_total}, Overall positive rate: {pos_rate_total:.4f}\",\n",
        "    f\"Sampling method: {SAMPLING_METHOD}\",\n",
        "    f\"Number of runs (K): {K_RUNS}\",\n",
        "    f\"Base seed (document for reproducibility): {BASE_SEED}\",\n",
        "    f\"Seeds used: {seeds}\",\n",
        "    \"\",\n",
        "    f\"Metrics per-run saved to: {METRICS_PER_RUN_CSV}\",\n",
        "    f\"Aggregated metrics saved to: {METRICS_AGG_CSV} (mean ± sd ± 95%CI)\",\n",
        "    f\"Top-K per-run saved to: {TOPK_PER_RUN_CSV}\",\n",
        "    f\"Top-K aggregated saved to: {TOPK_AGG_CSV}\",\n",
        "    f\"ROC plot (mean ± SD): {roc_path}\",\n",
        "    f\"PR plot (mean ± SD): {pr_path}\",\n",
        "    f\"Reliability plot (mean ± SD): {rel_path}\",\n",
        "    f\"Top-K plot (mean ± SD): {topk_plot_path}\",\n",
        "]\n",
        "if shap_outputs.get('top_feature'):\n",
        "    report_lines.append(f\"SHAP top feature (single-run model): {shap_outputs.get('top_feature')}\")\n",
        "with open(SUMMARY_TXT, 'w') as f:\n",
        "    f.write(\"\\n\".join(report_lines))\n",
        "\n",
        "print(\"\\n\".join(report_lines))\n",
        "print(\"Outputs written to:\", OUT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "756ea3ee"
      },
      "source": [],
      "id": "756ea3ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e6f0c25"
      },
      "source": [
        "To fix this, we can remove the existing content in the mountpoint before mounting the drive."
      ],
      "id": "3e6f0c25"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jintubhuyan-2000/ML-XAI_ForestFire/blob/main/Fire_Risk_RF_Model_Performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZkSBPUSlBXC8"
      },
      "id": "ZkSBPUSlBXC8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown --quiet\n",
        "\n",
        "# Use gdown to download the folder\n",
        "!gdown \"https://drive.google.com/drive/u/0/folders/1p-hZYcWiCIoc8Y0LRUPtqJJGe9_PjlFN\" --folder\n"
      ],
      "metadata": {
        "id": "colqvWoEQIjE",
        "outputId": "b802f07a-2e91-4a76-908a-577b95831e89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "colqvWoEQIjE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 1JLTkxujzAOyY8SPMLsua_QAED6_0f3yl FireRisk_Classes_RF__forest.csv\n",
            "Processing file 160nsutuW5crSeTbEhh9oAoA0HJa8n_cp FireRisk_Classes_RF__forest.png\n",
            "Processing file 10LD44_avGgopWeHNYxF2km35VpAjtDMS FireRisk_Classes_RF__grassland.csv\n",
            "Processing file 12_ewAIDHNIHp8xbSXDPGLJSPlAXialbV FireRisk_Classes_RF__grassland.png\n",
            "Processing file 1fwjdaRxAd07vDJ0Y7yaHPDbG-Exu2v6Q FireRisk_Classes_RF__grassland.tif\n",
            "Processing file 1acArgVbiC6laYQAJ-rGs6sCuXJ1PRZQ5 FireRisk_Classes_RF__grassland.tif.ovr\n",
            "Processing file 1kGbfN4DNVY5Skn_LAKFrzB9_hjEBTlkl FireRisk_Classes_RF__grassland.tif.vat.cpg\n",
            "Processing file 1HDP-h-AQVTgsXWv2vwR6qaBNEjeohFjN FireRisk_Classes_RF__grassland.tif.vat.dbf\n",
            "Processing file 1ahvmIzLK2JHcJhULl0z1c2RPP5ZqpGSl FireRisk_Classes_RF__grassland.tif.vat.dbf.JINTUMONIBHUYAN.25792.17896.sr.lock\n",
            "Processing file 1FXqqZBfK6idJjAiFFYlwGKVQVuEo11jy FireRisk_Classes_RF_Forest.tif\n",
            "Processing file 18jJuSulidTtDhiaVveC9DutEoj09DXI8 FireRisk_Classes_RF_Forest.tif.ovr\n",
            "Processing file 1Ers5oitfWL_8pJUgfBA6fmBkWv6b_bR3 FireRisk_Classes_RF_Forest.tif.vat.cpg\n",
            "Processing file 1_Du5PWyiXqP-GoiGFDUjyZ2ciBJ0peDy FireRisk_Classes_RF_Forest.tif.vat.dbf\n",
            "Processing file 15oBO85VRisOL8c8NcNzhbOY0afxDS1-o FireRisk_Classes_RF_Forest.tif.vat.dbf.JINTUMONIBHUYAN.25792.17896.sr.lock\n",
            "Processing file 14s3hyf44GuAX1jkVcXGWWF1MByWmIUyr FireRisk_Training_Samples_forest.csv\n",
            "Processing file 1ZiUZ5DgMPg_FBVVifq__BsqGhhR7HT3m FireRisk_Training_Samples_grassland.csv\n",
            "Processing file 1sNh9kFr89Z5g9eGDlK73vGbaaVyLP7yY FireRisk_Validation_Prob_forest.csv\n",
            "Processing file 1j3_XrtFpvF51QWKS3S_AFsSb9zZwdMnV FireRisk_Validation_Prob_grassland.csv\n",
            "Processing file 1THtPSXItgU60lRlFdbpVSzg04qLPo0co FireRisk_Validation_RF_AUC_forest.csv\n",
            "Processing file 1j1F3DmxIvQ9Q_4CUJbf14HUsL60OsMop FireRisk_Validation_RF_AUC_grassland.csv\n",
            "Processing file 1t9mmx-4SJAxPulsDZnmM2giWnuwe6j8x Random_Forest_Confusion_Matrix_f.png\n",
            "Processing file 15AJjTi9Q01EmHWsr_ptJVUxXT7gjp064 Random_Forest_Confusion_Matrix_g.png\n",
            "Processing file 15mqV0QyJexwr9exz-Cckt5iflaqKNLgZ Random_Forest_Confusion_Matrix.png\n",
            "Processing file 1oafIG_yGc0EHxwpkuCGXr32CcanoVVZh Random_Forest_PR_with_CI_f.png\n",
            "Processing file 1MZUq-u0Vf634EofJ8Wb_CDnMYf8T0zag Random_Forest_PR_with_CI_g.png\n",
            "Processing file 1CmNPVX9zHfQb6LwuNBMjRBLQzYvkN1q0 Random_Forest_PR_with_CI.png\n",
            "Processing file 14vuDsBkmBzGJSx-SRmFrRKQ8vC6cjIGQ Random_Forest_ROC_with_CI_f.png\n",
            "Processing file 1MQQqwl6oyzcLMYN2w46In9d_UymQ81ES Random_Forest_ROC_with_CI_g.png\n",
            "Processing file 177WtEe7MWJqpiNTo2KBifCn50w-lUVTF Random_Forest_ROC_with_CI.png\n",
            "Processing file 1WetxTOk1EY98kuOkQgVl0lzhdZyHdyYB RF_VariableImportance_forest.csv\n",
            "Processing file 1qlyBkwW1HLSw2PBnwvN_IVO93drtjsdc RF_VariableImportance_grassland.csv\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1JLTkxujzAOyY8SPMLsua_QAED6_0f3yl\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e6524c3-315c-4b7d-8174-7d7e4391b5ae",
      "metadata": {
        "id": "1e6524c3-315c-4b7d-8174-7d7e4391b5ae",
        "outputId": "8ff28de0-3e57-43c5-ad9e-a24cb8f229c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Random Forest Performance:\n",
            "AUC: 0.997, Accuracy: 0.949, Precision: 0.930, Recall: 0.997, F1: 0.963\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     No Fire       0.99      0.86      0.92       976\n",
            "        Fire       0.93      1.00      0.96      1879\n",
            "\n",
            "    accuracy                           0.95      2855\n",
            "   macro avg       0.96      0.93      0.94      2855\n",
            "weighted avg       0.95      0.95      0.95      2855\n",
            "\n",
            "âœ… Saved confusion matrix to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_RF_Model_Performance/Random_Forest_Confusion_Matrix.png\n",
            "âœ… Saved ROC curve with ribbon to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_RF_Model_Performance/Random_Forest_ROC_with_CI.png\n",
            "\n",
            "ðŸ“Š Random Forest Performance:\n",
            "AUC: 0.997, Accuracy: 0.949, Precision: 0.930, Recall: 0.997, F1: 0.963\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     No Fire       0.99      0.86      0.92       976\n",
            "        Fire       0.93      1.00      0.96      1879\n",
            "\n",
            "    accuracy                           0.95      2855\n",
            "   macro avg       0.96      0.93      0.94      2855\n",
            "weighted avg       0.95      0.95      0.95      2855\n",
            "\n",
            "âœ… Saved confusion matrix to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_RF_Model_Performance/Random_Forest_Confusion_Matrix.png\n",
            "âœ… Saved ROC curve with ribbon to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_RF_Model_Performance/Random_Forest_ROC_with_CI.png\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils import resample\n",
        "import os\n",
        "\n",
        "# ================================\n",
        "# ðŸ“ Define paths\n",
        "# ================================\n",
        "base_path = \"/content/drive/MyDrive/California_Fire_MS/Fire_Risk_RF_Model_Performance/Performance Data\"\n",
        "save_dir = \"/content/drive/MyDrive/California_Fire_MS/Fire_Risk_RF_Model_Performance/Results\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# ðŸ“„ Load ONLY RF CSV\n",
        "df_rf = pd.read_csv(os.path.join(base_path, \"FireRisk_Validation_RF_AUC_forest.csv\"))\n",
        "\n",
        "# ðŸ”§ Classification threshold\n",
        "threshold = 0.5\n",
        "\n",
        "# ================================\n",
        "# ðŸ“Š Evaluate Random Forest\n",
        "# ================================\n",
        "def evaluate_rf(df, model_name=\"Random Forest\", threshold=0.5, save_dir=\".\"):\n",
        "    y_true = df['class']\n",
        "    y_prob = df['probability']\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "\n",
        "    # ðŸ”¹ Metrics\n",
        "    auc = roc_auc_score(y_true, y_prob)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\nðŸ“Š {model_name} Performance:\")\n",
        "    print(f\"AUC: {auc:.3f}, Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
        "    print(classification_report(y_true, y_pred, target_names=[\"No Fire\", \"Fire\"]))\n",
        "\n",
        "    # ðŸ”¹ Confusion Matrix\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(confusion_matrix(y_true, y_pred),\n",
        "                annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=[\"No Fire\", \"Fire\"],\n",
        "                yticklabels=[\"No Fire\", \"Fire\"])\n",
        "    plt.title(f\"{model_name} - Confusion Matrix\", fontsize=16, fontweight='bold')\n",
        "    plt.xlabel(\"Predicted\", fontsize=16)\n",
        "    plt.ylabel(\"Actual\", fontsize=16)\n",
        "    plt.xticks(fontsize=14)\n",
        "    plt.yticks(fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    cm_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_Confusion_Matrix.png\")\n",
        "    plt.savefig(cm_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"âœ… Saved confusion matrix to: {cm_path}\")\n",
        "\n",
        "    return y_true.values, y_prob.values, auc\n",
        "\n",
        "# ================================\n",
        "# ðŸŽ¨ ROC with Bootstrapped Ribbon\n",
        "# ================================\n",
        "def plot_roc_with_ci(y_true, y_prob, model_name=\"Random Forest\", save_dir=\".\", n_bootstraps=1000):\n",
        "    rng = np.random.RandomState(42)\n",
        "    fpr_grid = np.linspace(0, 1, 100)\n",
        "\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "\n",
        "    # Bootstrapping\n",
        "    for i in range(n_bootstraps):\n",
        "        indices = rng.randint(0, len(y_true), len(y_true))\n",
        "        if len(np.unique(y_true[indices])) < 2:\n",
        "            continue\n",
        "        y_true_boot = y_true[indices]\n",
        "        y_prob_boot = y_prob[indices]\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_true_boot, y_prob_boot)\n",
        "        tpr_interp = np.interp(fpr_grid, fpr, tpr)\n",
        "        tpr_interp[0] = 0.0\n",
        "        tprs.append(tpr_interp)\n",
        "        aucs.append(roc_auc_score(y_true_boot, y_prob_boot))\n",
        "\n",
        "    tprs = np.array(tprs)\n",
        "    mean_tpr = tprs.mean(axis=0)\n",
        "    std_tpr = tprs.std(axis=0)\n",
        "\n",
        "    mean_auc = np.mean(aucs)\n",
        "    std_auc = np.std(aucs)\n",
        "\n",
        "    # Upper and lower bound\n",
        "    tpr_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "    tpr_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.plot(fpr_grid, mean_tpr, color='darkgreen', lw=2,\n",
        "             label=f\"Mean ROC (AUC = {mean_auc:.3f} Â± {std_auc:.3f})\")\n",
        "    plt.fill_between(fpr_grid, tpr_lower, tpr_upper, color='green', alpha=0.2, label='Â±1 SD')\n",
        "    plt.plot([0,1],[0,1], 'k--', lw=1, label='No Skill')\n",
        "\n",
        "    # Styling\n",
        "    plt.xlabel(\"False Positive Rate\", fontsize=18)\n",
        "    plt.ylabel(\"True Positive Rate\", fontsize=16)\n",
        "    plt.title(f\"ROC Curve with Confidence Interval - {model_name}\", fontsize=18, fontweight='bold')\n",
        "    plt.legend(loc=\"lower right\", fontsize=18)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.xticks(fontsize=18)\n",
        "    plt.yticks(fontsize=18)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save\n",
        "    roc_ci_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_ROC_with_CI.png\")\n",
        "    plt.savefig(roc_ci_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"âœ… Saved ROC curve with ribbon to: {roc_ci_path}\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "# ðŸš€ Run\n",
        "# ================================\n",
        "y_true_rf, y_prob_rf, auc_rf = evaluate_rf(df_rf, save_dir=save_dir)\n",
        "plot_roc_with_ci(y_true_rf, y_prob_rf, save_dir=save_dir)\n",
        "# ================================\n",
        "# ðŸ“Š Evaluate Random Forest\n",
        "# ================================\n",
        "def evaluate_rf(df, model_name=\"Random Forest\", threshold=0.5, save_dir=\".\"):\n",
        "    y_true = df['class']\n",
        "    y_prob = df['probability']\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "\n",
        "    # ðŸ”¹ Metrics\n",
        "    auc = roc_auc_score(y_true, y_prob)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\nðŸ“Š {model_name} Performance:\")\n",
        "    print(f\"AUC: {auc:.3f}, Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
        "    print(classification_report(y_true, y_pred, target_names=[\"No Fire\", \"Fire\"]))\n",
        "\n",
        "    # ðŸ”¹ Confusion Matrix\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(confusion_matrix(y_true, y_pred),\n",
        "                annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=[\"No Fire\", \"Fire\"],\n",
        "                yticklabels=[\"No Fire\", \"Fire\"])\n",
        "    plt.title(f\"{model_name} - Confusion Matrix\", fontsize=16, fontweight='bold')\n",
        "    plt.xlabel(\"Predicted\", fontsize=18)\n",
        "    plt.ylabel(\"Actual\", fontsize=18)\n",
        "    plt.xticks(fontsize=18)\n",
        "    plt.yticks(fontsize=18)\n",
        "    plt.tight_layout()\n",
        "    cm_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_Confusion_Matrix.png\")\n",
        "    plt.savefig(cm_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"âœ… Saved confusion matrix to: {cm_path}\")\n",
        "\n",
        "    return y_true.values, y_prob.values, auc\n",
        "\n",
        "# ================================\n",
        "# ðŸŽ¨ ROC with Bootstrapped Ribbon\n",
        "# ================================\n",
        "def plot_roc_with_ci(y_true, y_prob, model_name=\"Random Forest\", save_dir=\".\", n_bootstraps=1000):\n",
        "    rng = np.random.RandomState(42)\n",
        "    fpr_grid = np.linspace(0, 1, 100)\n",
        "\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "\n",
        "    # Bootstrapping\n",
        "    for i in range(n_bootstraps):\n",
        "        indices = rng.randint(0, len(y_true), len(y_true))\n",
        "        if len(np.unique(y_true[indices])) < 2:\n",
        "            continue\n",
        "        y_true_boot = y_true[indices]\n",
        "        y_prob_boot = y_prob[indices]\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_true_boot, y_prob_boot)\n",
        "        tpr_interp = np.interp(fpr_grid, fpr, tpr)\n",
        "        tpr_interp[0] = 0.0\n",
        "        tprs.append(tpr_interp)\n",
        "        aucs.append(roc_auc_score(y_true_boot, y_prob_boot))\n",
        "\n",
        "    tprs = np.array(tprs)\n",
        "    mean_tpr = tprs.mean(axis=0)\n",
        "    std_tpr = tprs.std(axis=0)\n",
        "\n",
        "    mean_auc = np.mean(aucs)\n",
        "    std_auc = np.std(aucs)\n",
        "\n",
        "    # Upper and lower bound\n",
        "    tpr_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "    tpr_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.plot(fpr_grid, mean_tpr, color='darkgreen', lw=2,\n",
        "             label=f\"Mean ROC (AUC = {mean_auc:.3f} Â± {std_auc:.3f})\")\n",
        "    plt.fill_between(fpr_grid, tpr_lower, tpr_upper, color='green', alpha=0.2, label='Â±1 SD')\n",
        "    plt.plot([0,1],[0,1], 'k--', lw=1, label='No Skill')\n",
        "\n",
        "    # Styling\n",
        "    plt.xlabel(\"False Positive Rate\", fontsize=18)\n",
        "    plt.ylabel(\"True Positive Rate\", fontsize=18)\n",
        "    plt.title(f\"ROC Curve with Confidence Interval - {model_name}\", fontsize=18, fontweight='bold')\n",
        "    plt.legend(loc=\"lower right\", fontsize=1)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.xticks(fontsize=1)\n",
        "    plt.yticks(fontsize=18)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save\n",
        "    roc_ci_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_ROC_with_CI.png\")\n",
        "    plt.savefig(roc_ci_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"âœ… Saved ROC curve with ribbon to: {roc_ci_path}\")\n",
        "\n",
        "\n",
        "# ================================\n",
        "# ðŸš€ Run\n",
        "# ================================\n",
        "y_true_rf, y_prob_rf, auc_rf = evaluate_rf(df_rf, save_dir=save_dir)\n",
        "plot_roc_with_ci(y_true_rf, y_prob_rf, save_dir=save_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee2d3c3b-534f-444e-b94a-e92d8a48391b",
      "metadata": {
        "id": "ee2d3c3b-534f-444e-b94a-e92d8a48391b",
        "outputId": "23e04589-d2b0-4e06-f47d-2ba9464203ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Random Forest Performance:\n",
            "AUC: 0.997, Accuracy: 0.949, Precision: 0.930, Recall: 0.997, F1: 0.963\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     No Fire       0.99      0.86      0.92       976\n",
            "        Fire       0.93      1.00      0.96      1879\n",
            "\n",
            "    accuracy                           0.95      2855\n",
            "   macro avg       0.96      0.93      0.94      2855\n",
            "weighted avg       0.95      0.95      0.95      2855\n",
            "\n",
            "âœ… Saved confusion matrix to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_RF_Model_Performance/Random_Forest_Confusion_Matrix.png\n",
            "âœ… Saved ROC curve with ribbon to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_RF_Model_Performance/Random_Forest_ROC_with_CI.png\n",
            "âœ… Saved Precision-Recall curve with ribbon to: /content/drive/MyDrive/California_Fire_MS/Fire_Risk_RF_Model_Performance/Random_Forest_PR_with_CI.png\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils import resample\n",
        "import os\n",
        "\n",
        "# ================================\n",
        "# ðŸ“ Define paths\n",
        "# ================================\n",
        "base_path = \"/content/drive/MyDrive/California_Fire_MS/Fire_Risk_RF_Model_Performance/Performance Data\"\n",
        "save_dir = \"/content/drive/MyDrive/California_Fire_MS/Fire_Risk_RF_Model_Performance/Results\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# ðŸ“„ Load ONLY RF CSV\n",
        "df_rf = pd.read_csv(os.path.join(base_path, \"FireRisk_Validation_RF_AUC_forest.csv\"))\n",
        "\n",
        "# ðŸ”§ Classification threshold\n",
        "threshold = 0.5\n",
        "\n",
        "# ================================\n",
        "# ðŸ“Š Evaluate Random Forest\n",
        "# ================================\n",
        "def evaluate_rf(df, model_name=\"Random Forest\", threshold=0.5, save_dir=\".\"):\n",
        "    y_true = df['class']\n",
        "    y_prob = df['probability']\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "\n",
        "    # ðŸ”¹ Metrics\n",
        "    auc = roc_auc_score(y_true, y_prob)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\nðŸ“Š {model_name} Performance:\")\n",
        "    print(f\"AUC: {auc:.3f}, Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
        "    print(classification_report(y_true, y_pred, target_names=[\"No Fire\", \"Fire\"]))\n",
        "\n",
        "    # ðŸ”¹ Confusion Matrix\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(confusion_matrix(y_true, y_pred),\n",
        "                annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=[\"No Fire\", \"Fire\"],\n",
        "                yticklabels=[\"No Fire\", \"Fire\"])\n",
        "    plt.title(f\"{model_name} - Confusion Matrix\", fontsize=18, fontweight='bold')\n",
        "    plt.xlabel(\"Predicted\", fontsize=18)\n",
        "    plt.ylabel(\"Actual\", fontsize=18)\n",
        "    plt.xticks(fontsize=18)\n",
        "    plt.yticks(fontsize=18)\n",
        "    plt.tight_layout()\n",
        "    cm_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_Confusion_Matrix.png\")\n",
        "    plt.savefig(cm_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"âœ… Saved confusion matrix to: {cm_path}\")\n",
        "\n",
        "    return y_true.values, y_prob.values, auc\n",
        "\n",
        "# ================================\n",
        "# ðŸŽ¨ ROC with Bootstrapped Ribbon\n",
        "# ================================\n",
        "def plot_roc_with_ci(y_true, y_prob, model_name=\"Random Forest\", save_dir=\".\", n_bootstraps=1000):\n",
        "    rng = np.random.RandomState(42)\n",
        "    fpr_grid = np.linspace(0, 1, 100)\n",
        "    tprs, aucs = [], []\n",
        "\n",
        "    for _ in range(n_bootstraps):\n",
        "        indices = rng.randint(0, len(y_true), len(y_true))\n",
        "        if len(np.unique(y_true[indices])) < 2:  # skip if only one class\n",
        "            continue\n",
        "        y_true_boot = y_true[indices]\n",
        "        y_prob_boot = y_prob[indices]\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_true_boot, y_prob_boot)\n",
        "        tpr_interp = np.interp(fpr_grid, fpr, tpr)\n",
        "        tpr_interp[0] = 0.0\n",
        "        tprs.append(tpr_interp)\n",
        "        aucs.append(roc_auc_score(y_true_boot, y_prob_boot))\n",
        "\n",
        "    tprs = np.array(tprs)\n",
        "    mean_tpr = tprs.mean(axis=0)\n",
        "    std_tpr = tprs.std(axis=0)\n",
        "    tpr_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "    tpr_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "\n",
        "    mean_auc = np.mean(aucs)\n",
        "    std_auc = np.std(aucs)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.plot(fpr_grid, mean_tpr, color='darkgreen', lw=2,\n",
        "             label=f\"Mean ROC (AUC = {mean_auc:.3f} Â± {std_auc:.3f})\")\n",
        "    plt.fill_between(fpr_grid, tpr_lower, tpr_upper, color='green', alpha=0.2, label='Â±1 SD')\n",
        "    plt.plot([0,1],[0,1], 'k--', lw=1, label='No Skill')\n",
        "\n",
        "    plt.xlabel(\"False Positive Rate\", fontsize=18)\n",
        "    plt.ylabel(\"True Positive Rate\", fontsize=18)\n",
        "    plt.title(f\"ROC Curve with Confidence Interval \", fontsize=18, fontweight='bold')\n",
        "    plt.legend(loc=\"lower right\", fontsize=18)\n",
        "    plt.xticks(fontsize=18)\n",
        "    plt.yticks(fontsize=18)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    roc_ci_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_ROC_with_CI.png\")\n",
        "    plt.savefig(roc_ci_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"âœ… Saved ROC curve with ribbon to: {roc_ci_path}\")\n",
        "\n",
        "# ================================\n",
        "# ðŸŽ¨ Precision-Recall Curve with Bootstrapped Ribbon\n",
        "# ================================\n",
        "def plot_pr_with_ci(y_true, y_prob, model_name=\"Random Forest\", save_dir=\".\", n_bootstraps=1000):\n",
        "    rng = np.random.RandomState(42)\n",
        "    recall_grid = np.linspace(0, 1, 100)\n",
        "    precisions = []\n",
        "\n",
        "    for _ in range(n_bootstraps):\n",
        "        indices = rng.randint(0, len(y_true), len(y_true))\n",
        "        if len(np.unique(y_true[indices])) < 2:\n",
        "            continue\n",
        "        y_true_boot = y_true[indices]\n",
        "        y_prob_boot = y_prob[indices]\n",
        "\n",
        "        precision, recall, _ = precision_recall_curve(y_true_boot, y_prob_boot)\n",
        "        precision_interp = np.interp(recall_grid, recall[::-1], precision[::-1])\n",
        "        precisions.append(precision_interp)\n",
        "\n",
        "    precisions = np.array(precisions)\n",
        "    mean_precision = precisions.mean(axis=0)\n",
        "    std_precision = precisions.std(axis=0)\n",
        "    precision_upper = np.minimum(mean_precision + std_precision, 1)\n",
        "    precision_lower = np.maximum(mean_precision - std_precision, 0)\n",
        "\n",
        "    baseline = np.mean(y_true)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.plot(recall_grid, mean_precision, color='darkblue', lw=2, label=\"Mean PR Curve\")\n",
        "    plt.fill_between(recall_grid, precision_lower, precision_upper, color='blue', alpha=0.2, label='Â±1 SD')\n",
        "    plt.hlines(baseline, 0, 1, color='gray', linestyle='--', label='No Skill')\n",
        "\n",
        "    plt.xlabel(\"Recall\", fontsize=18)\n",
        "    plt.ylabel(\"Precision\", fontsize=18)\n",
        "    plt.title(f\"Precision-Recall Curve with Confidence Interval\", fontsize=18, fontweight='bold')\n",
        "    plt.legend(loc=\"lower left\", fontsize=18)\n",
        "    plt.xticks(fontsize=18)\n",
        "    plt.yticks(fontsize=18)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    pr_ci_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_PR_with_CI.png\")\n",
        "    plt.savefig(pr_ci_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"âœ… Saved Precision-Recall curve with ribbon to: {pr_ci_path}\")\n",
        "\n",
        "# ================================\n",
        "# ðŸš€ Run\n",
        "# ================================\n",
        "y_true_rf, y_prob_rf, auc_rf = evaluate_rf(df_rf, save_dir=save_dir)\n",
        "plot_roc_with_ci(y_true_rf, y_prob_rf, save_dir=save_dir)\n",
        "plot_pr_with_ci(y_true_rf, y_prob_rf, save_dir=save_dir)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e6524c3-315c-4b7d-8174-7d7e4391b5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Random Forest Performance:\n",
      "AUC: 0.997, Accuracy: 0.949, Precision: 0.930, Recall: 0.997, F1: 0.963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Fire       0.99      0.86      0.92       976\n",
      "        Fire       0.93      1.00      0.96      1879\n",
      "\n",
      "    accuracy                           0.95      2855\n",
      "   macro avg       0.96      0.93      0.94      2855\n",
      "weighted avg       0.95      0.95      0.95      2855\n",
      "\n",
      "âœ… Saved confusion matrix to: E:\\Freelancing\\WildFire_Paper_CA\\Revised_08092025\\Fire_Risk_RF_12092025\\Random_Forest_Confusion_Matrix.png\n",
      "âœ… Saved ROC curve with ribbon to: E:\\Freelancing\\WildFire_Paper_CA\\Revised_08092025\\Fire_Risk_RF_12092025\\Random_Forest_ROC_with_CI.png\n",
      "\n",
      "ðŸ“Š Random Forest Performance:\n",
      "AUC: 0.997, Accuracy: 0.949, Precision: 0.930, Recall: 0.997, F1: 0.963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Fire       0.99      0.86      0.92       976\n",
      "        Fire       0.93      1.00      0.96      1879\n",
      "\n",
      "    accuracy                           0.95      2855\n",
      "   macro avg       0.96      0.93      0.94      2855\n",
      "weighted avg       0.95      0.95      0.95      2855\n",
      "\n",
      "âœ… Saved confusion matrix to: E:\\Freelancing\\WildFire_Paper_CA\\Revised_08092025\\Fire_Risk_RF_12092025\\Random_Forest_Confusion_Matrix.png\n",
      "âœ… Saved ROC curve with ribbon to: E:\\Freelancing\\WildFire_Paper_CA\\Revised_08092025\\Fire_Risk_RF_12092025\\Random_Forest_ROC_with_CI.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "\n",
    "# ================================\n",
    "# ðŸ“ Define paths\n",
    "# ================================\n",
    "base_path = \"E:\\Freelancing\\WildFire_Paper_CA\\Revised_08092025\\Fire_Risk_RF_12092025\"\n",
    "save_dir = base_path\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ðŸ“„ Load ONLY RF CSV\n",
    "df_rf = pd.read_csv(os.path.join(base_path, \"FireRisk_Validation_RF_AUC_forest.csv\"))\n",
    "\n",
    "# ðŸ”§ Classification threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# ================================\n",
    "# ðŸ“Š Evaluate Random Forest\n",
    "# ================================\n",
    "def evaluate_rf(df, model_name=\"Random Forest\", threshold=0.5, save_dir=\".\"):\n",
    "    y_true = df['class']\n",
    "    y_prob = df['probability']\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # ðŸ”¹ Metrics\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nðŸ“Š {model_name} Performance:\")\n",
    "    print(f\"AUC: {auc:.3f}, Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"No Fire\", \"Fire\"]))\n",
    "\n",
    "    # ðŸ”¹ Confusion Matrix\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred),\n",
    "                annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"No Fire\", \"Fire\"],\n",
    "                yticklabels=[\"No Fire\", \"Fire\"])\n",
    "    plt.title(f\"{model_name} - Confusion Matrix\", fontsize=16, fontweight='bold')\n",
    "    plt.xlabel(\"Predicted\", fontsize=16)\n",
    "    plt.ylabel(\"Actual\", fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cm_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_Confusion_Matrix.png\")\n",
    "    plt.savefig(cm_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"âœ… Saved confusion matrix to: {cm_path}\")\n",
    "\n",
    "    return y_true.values, y_prob.values, auc\n",
    "\n",
    "# ================================\n",
    "# ðŸŽ¨ ROC with Bootstrapped Ribbon\n",
    "# ================================\n",
    "def plot_roc_with_ci(y_true, y_prob, model_name=\"Random Forest\", save_dir=\".\", n_bootstraps=1000):\n",
    "    rng = np.random.RandomState(42)\n",
    "    fpr_grid = np.linspace(0, 1, 100)\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "\n",
    "    # Bootstrapping\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        y_true_boot = y_true[indices]\n",
    "        y_prob_boot = y_prob[indices]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true_boot, y_prob_boot)\n",
    "        tpr_interp = np.interp(fpr_grid, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0\n",
    "        tprs.append(tpr_interp)\n",
    "        aucs.append(roc_auc_score(y_true_boot, y_prob_boot))\n",
    "\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tpr = tprs.mean(axis=0)\n",
    "    std_tpr = tprs.std(axis=0)\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    # Upper and lower bound\n",
    "    tpr_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tpr_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(7,6))\n",
    "    plt.plot(fpr_grid, mean_tpr, color='darkgreen', lw=2,\n",
    "             label=f\"Mean ROC (AUC = {mean_auc:.3f} Â± {std_auc:.3f})\")\n",
    "    plt.fill_between(fpr_grid, tpr_lower, tpr_upper, color='green', alpha=0.2, label='Â±1 SD')\n",
    "    plt.plot([0,1],[0,1], 'k--', lw=1, label='No Skill')\n",
    "\n",
    "    # Styling\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=18)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=16)\n",
    "    plt.title(f\"ROC Curve with Confidence Interval - {model_name}\", fontsize=18, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=18)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save\n",
    "    roc_ci_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_ROC_with_CI.png\")\n",
    "    plt.savefig(roc_ci_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"âœ… Saved ROC curve with ribbon to: {roc_ci_path}\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# ðŸš€ Run\n",
    "# ================================\n",
    "y_true_rf, y_prob_rf, auc_rf = evaluate_rf(df_rf, save_dir=save_dir)\n",
    "plot_roc_with_ci(y_true_rf, y_prob_rf, save_dir=save_dir)\n",
    "# ================================\n",
    "# ðŸ“Š Evaluate Random Forest\n",
    "# ================================\n",
    "def evaluate_rf(df, model_name=\"Random Forest\", threshold=0.5, save_dir=\".\"):\n",
    "    y_true = df['class']\n",
    "    y_prob = df['probability']\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # ðŸ”¹ Metrics\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nðŸ“Š {model_name} Performance:\")\n",
    "    print(f\"AUC: {auc:.3f}, Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"No Fire\", \"Fire\"]))\n",
    "\n",
    "    # ðŸ”¹ Confusion Matrix\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred),\n",
    "                annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"No Fire\", \"Fire\"],\n",
    "                yticklabels=[\"No Fire\", \"Fire\"])\n",
    "    plt.title(f\"{model_name} - Confusion Matrix\", fontsize=16, fontweight='bold')\n",
    "    plt.xlabel(\"Predicted\", fontsize=18)\n",
    "    plt.ylabel(\"Actual\", fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    cm_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_Confusion_Matrix.png\")\n",
    "    plt.savefig(cm_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"âœ… Saved confusion matrix to: {cm_path}\")\n",
    "\n",
    "    return y_true.values, y_prob.values, auc\n",
    "\n",
    "# ================================\n",
    "# ðŸŽ¨ ROC with Bootstrapped Ribbon\n",
    "# ================================\n",
    "def plot_roc_with_ci(y_true, y_prob, model_name=\"Random Forest\", save_dir=\".\", n_bootstraps=1000):\n",
    "    rng = np.random.RandomState(42)\n",
    "    fpr_grid = np.linspace(0, 1, 100)\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "\n",
    "    # Bootstrapping\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        y_true_boot = y_true[indices]\n",
    "        y_prob_boot = y_prob[indices]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true_boot, y_prob_boot)\n",
    "        tpr_interp = np.interp(fpr_grid, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0\n",
    "        tprs.append(tpr_interp)\n",
    "        aucs.append(roc_auc_score(y_true_boot, y_prob_boot))\n",
    "\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tpr = tprs.mean(axis=0)\n",
    "    std_tpr = tprs.std(axis=0)\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    # Upper and lower bound\n",
    "    tpr_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tpr_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(7,6))\n",
    "    plt.plot(fpr_grid, mean_tpr, color='darkgreen', lw=2,\n",
    "             label=f\"Mean ROC (AUC = {mean_auc:.3f} Â± {std_auc:.3f})\")\n",
    "    plt.fill_between(fpr_grid, tpr_lower, tpr_upper, color='green', alpha=0.2, label='Â±1 SD')\n",
    "    plt.plot([0,1],[0,1], 'k--', lw=1, label='No Skill')\n",
    "\n",
    "    # Styling\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=18)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=18)\n",
    "    plt.title(f\"ROC Curve with Confidence Interval - {model_name}\", fontsize=18, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=1)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.xticks(fontsize=1)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save\n",
    "    roc_ci_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_ROC_with_CI.png\")\n",
    "    plt.savefig(roc_ci_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"âœ… Saved ROC curve with ribbon to: {roc_ci_path}\")\n",
    "\n",
    "\n",
    "# ================================\n",
    "# ðŸš€ Run\n",
    "# ================================\n",
    "y_true_rf, y_prob_rf, auc_rf = evaluate_rf(df_rf, save_dir=save_dir)\n",
    "plot_roc_with_ci(y_true_rf, y_prob_rf, save_dir=save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee2d3c3b-534f-444e-b94a-e92d8a48391b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Random Forest Performance:\n",
      "AUC: 0.997, Accuracy: 0.949, Precision: 0.930, Recall: 0.997, F1: 0.963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Fire       0.99      0.86      0.92       976\n",
      "        Fire       0.93      1.00      0.96      1879\n",
      "\n",
      "    accuracy                           0.95      2855\n",
      "   macro avg       0.96      0.93      0.94      2855\n",
      "weighted avg       0.95      0.95      0.95      2855\n",
      "\n",
      "âœ… Saved confusion matrix to: E:/Freelancing/WildFire_Paper_CA/Revised_08092025/Fire_Risk_RF_12092025\\Random_Forest_Confusion_Matrix.png\n",
      "âœ… Saved ROC curve with ribbon to: E:/Freelancing/WildFire_Paper_CA/Revised_08092025/Fire_Risk_RF_12092025\\Random_Forest_ROC_with_CI.png\n",
      "âœ… Saved Precision-Recall curve with ribbon to: E:/Freelancing/WildFire_Paper_CA/Revised_08092025/Fire_Risk_RF_12092025\\Random_Forest_PR_with_CI.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "\n",
    "# ================================\n",
    "# ðŸ“ Define paths\n",
    "# ================================\n",
    "base_path = \"E:/Freelancing/WildFire_Paper_CA/Revised_08092025/Fire_Risk_RF_12092025\"\n",
    "save_dir = base_path\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ðŸ“„ Load ONLY RF CSV\n",
    "df_rf = pd.read_csv(os.path.join(base_path, \"FireRisk_Validation_RF_AUC_forest.csv\"))\n",
    "\n",
    "# ðŸ”§ Classification threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# ================================\n",
    "# ðŸ“Š Evaluate Random Forest\n",
    "# ================================\n",
    "def evaluate_rf(df, model_name=\"Random Forest\", threshold=0.5, save_dir=\".\"):\n",
    "    y_true = df['class']\n",
    "    y_prob = df['probability']\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # ðŸ”¹ Metrics\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nðŸ“Š {model_name} Performance:\")\n",
    "    print(f\"AUC: {auc:.3f}, Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"No Fire\", \"Fire\"]))\n",
    "\n",
    "    # ðŸ”¹ Confusion Matrix\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred),\n",
    "                annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"No Fire\", \"Fire\"],\n",
    "                yticklabels=[\"No Fire\", \"Fire\"])\n",
    "    plt.title(f\"{model_name} - Confusion Matrix\", fontsize=18, fontweight='bold')\n",
    "    plt.xlabel(\"Predicted\", fontsize=18)\n",
    "    plt.ylabel(\"Actual\", fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    cm_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_Confusion_Matrix.png\")\n",
    "    plt.savefig(cm_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"âœ… Saved confusion matrix to: {cm_path}\")\n",
    "\n",
    "    return y_true.values, y_prob.values, auc\n",
    "\n",
    "# ================================\n",
    "# ðŸŽ¨ ROC with Bootstrapped Ribbon\n",
    "# ================================\n",
    "def plot_roc_with_ci(y_true, y_prob, model_name=\"Random Forest\", save_dir=\".\", n_bootstraps=1000):\n",
    "    rng = np.random.RandomState(42)\n",
    "    fpr_grid = np.linspace(0, 1, 100)\n",
    "    tprs, aucs = [], []\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[indices])) < 2:  # skip if only one class\n",
    "            continue\n",
    "        y_true_boot = y_true[indices]\n",
    "        y_prob_boot = y_prob[indices]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true_boot, y_prob_boot)\n",
    "        tpr_interp = np.interp(fpr_grid, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0\n",
    "        tprs.append(tpr_interp)\n",
    "        aucs.append(roc_auc_score(y_true_boot, y_prob_boot))\n",
    "\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tpr = tprs.mean(axis=0)\n",
    "    std_tpr = tprs.std(axis=0)\n",
    "    tpr_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tpr_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(7,6))\n",
    "    plt.plot(fpr_grid, mean_tpr, color='darkgreen', lw=2,\n",
    "             label=f\"Mean ROC (AUC = {mean_auc:.3f} Â± {std_auc:.3f})\")\n",
    "    plt.fill_between(fpr_grid, tpr_lower, tpr_upper, color='green', alpha=0.2, label='Â±1 SD')\n",
    "    plt.plot([0,1],[0,1], 'k--', lw=1, label='No Skill')\n",
    "\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=18)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=18)\n",
    "    plt.title(f\"ROC Curve with Confidence Interval \", fontsize=18, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    roc_ci_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_ROC_with_CI.png\")\n",
    "    plt.savefig(roc_ci_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"âœ… Saved ROC curve with ribbon to: {roc_ci_path}\")\n",
    "\n",
    "# ================================\n",
    "# ðŸŽ¨ Precision-Recall Curve with Bootstrapped Ribbon\n",
    "# ================================\n",
    "def plot_pr_with_ci(y_true, y_prob, model_name=\"Random Forest\", save_dir=\".\", n_bootstraps=1000):\n",
    "    rng = np.random.RandomState(42)\n",
    "    recall_grid = np.linspace(0, 1, 100)\n",
    "    precisions = []\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_true), len(y_true))\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        y_true_boot = y_true[indices]\n",
    "        y_prob_boot = y_prob[indices]\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_true_boot, y_prob_boot)\n",
    "        precision_interp = np.interp(recall_grid, recall[::-1], precision[::-1])\n",
    "        precisions.append(precision_interp)\n",
    "\n",
    "    precisions = np.array(precisions)\n",
    "    mean_precision = precisions.mean(axis=0)\n",
    "    std_precision = precisions.std(axis=0)\n",
    "    precision_upper = np.minimum(mean_precision + std_precision, 1)\n",
    "    precision_lower = np.maximum(mean_precision - std_precision, 0)\n",
    "\n",
    "    baseline = np.mean(y_true)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(7,6))\n",
    "    plt.plot(recall_grid, mean_precision, color='darkblue', lw=2, label=\"Mean PR Curve\")\n",
    "    plt.fill_between(recall_grid, precision_lower, precision_upper, color='blue', alpha=0.2, label='Â±1 SD')\n",
    "    plt.hlines(baseline, 0, 1, color='gray', linestyle='--', label='No Skill')\n",
    "\n",
    "    plt.xlabel(\"Recall\", fontsize=18)\n",
    "    plt.ylabel(\"Precision\", fontsize=18)\n",
    "    plt.title(f\"Precision-Recall Curve with Confidence Interval\", fontsize=18, fontweight='bold')\n",
    "    plt.legend(loc=\"lower left\", fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    pr_ci_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_PR_with_CI.png\")\n",
    "    plt.savefig(pr_ci_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"âœ… Saved Precision-Recall curve with ribbon to: {pr_ci_path}\")\n",
    "\n",
    "# ================================\n",
    "# ðŸš€ Run\n",
    "# ================================\n",
    "y_true_rf, y_prob_rf, auc_rf = evaluate_rf(df_rf, save_dir=save_dir)\n",
    "plot_roc_with_ci(y_true_rf, y_prob_rf, save_dir=save_dir)\n",
    "plot_pr_with_ci(y_true_rf, y_prob_rf, save_dir=save_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
